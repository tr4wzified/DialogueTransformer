using Mutagen.Bethesda;
using Mutagen.Bethesda.Synthesis;
using Mutagen.Bethesda.Skyrim;
using CsvHelper;
using System.Globalization;
using Mutagen.Bethesda.Plugins;
using DialogueTransformer.Common.Models;
using DialogueTransformer.Common;
using System.Diagnostics;
using System.Collections.Concurrent;
using System.Runtime.InteropServices;
using System.Reflection;
using static DialogueTransformer.Common.Enumerations;

namespace DialogueTransformer.Patcher
{
    public class Program
    {
        static Lazy<Settings> Settings = null!;

        public static async Task<int> Main(string[] args)
        {
            return await SynthesisPipeline.Instance
                .AddPatch<ISkyrimMod, ISkyrimModGetter>(RunPatch)
                .SetAutogeneratedSettings(
                    nickname: "Settings",
                    path: "settings.json",
                    out Settings)
                .SetTypicalOpen(GameRelease.SkyrimSE, $"DialogueTransformer.esp")
                .Run(args);
        }

        public static async void RunPatch(IPatcherState<ISkyrimMod, ISkyrimModGetter> state)
        {

            if (!state.InternalDataPath.HasValue)
                throw new Exception("InternalDataPath was null - patcher cannot function!");

            Console.WriteLine($"Running DialogueTransformer by trawzified");

            var availableModels = Helper.GetModels(state.DataFolderPath);
            var selectedModel = availableModels[Settings.Value.Model];
            if (!selectedModel.Installed)
                throw new Exception($"Selected model {Settings.Value.Model}, but it's not installed! Exiting. You can download it here: {selectedModel.DownloadUrl}");

            Dictionary<string, List<IDialogTopicGetter>> dialogueNeedingInferencing = new();

            foreach (var dialogTopic in state.LoadOrder.PriorityOrder.DialogTopic().WinningContextOverrides())
            {
                var name = dialogTopic.Record.Name?.String;
                if (string.IsNullOrWhiteSpace(name))
                    continue;

                // First try to use the previously translated records from analyzed Khajiit patches
                if (Settings.Value.UseOverrides && selectedModel.Overrides.TryGetValue(dialogTopic.Record.FormKey, out var dialogTranslation))
                {
                    var translatedDialog = dialogTopic.Record.DeepCopy();
                    translatedDialog.Name = dialogTranslation.TargetText;
                    state.PatchMod.DialogTopics.GetOrAddAsOverride(translatedDialog);
                    continue;
                }

                // Check if this is a sentence or just some unused keyword kinda thing, if none of these characters are in the string just skip it to save useless processing time on the language model
                if (name.StartsWith('(') || name.IndexOf(' ') == -1 || name.IndexOfAny(new char[] { '.', '?', '!' }) == -1)
                    continue;

                if (dialogueNeedingInferencing.TryGetValue(name, out var dialogTopics))
                    dialogTopics.Add(dialogTopic.Record);
                else
                    dialogueNeedingInferencing[name] = new List<IDialogTopicGetter>() { dialogTopic.Record };
            }

            if (!dialogueNeedingInferencing.Any())
            {
                Console.WriteLine("Patching complete as no dialogue needs inferencing.");
                return;
            }

            var inferencorPath = Path.Combine(state.InternalDataPath, "DialoguePredictor");


            ConcurrentDictionary<string, string> preCache = new(selectedModel.PreCache);
            int cachedCount = 0;
            if (preCache.Any())
            {
                Console.WriteLine($"Found {preCache.Count} pre-cached dialogue records");
                Console.WriteLine($"Subtracting the pre-cached records from the queue ({dialogueNeedingInferencing.Count} records)...");
                foreach (var cacheRecord in preCache)
                {
                    if (dialogueNeedingInferencing.TryGetValue(cacheRecord.Key, out var dialogTopicGetters))
                    {
                        foreach (var dialogTopicGetter in dialogTopicGetters)
                        {
                            var recordCopy = dialogTopicGetter.DeepCopy();
                            recordCopy.Name = cacheRecord.Value;
                            state.PatchMod.DialogTopics.GetOrAddAsOverride(recordCopy);
                            cachedCount++;
                        }
                        dialogueNeedingInferencing.Remove(cacheRecord.Key);
                    }
                }
            }

            if (dialogueNeedingInferencing.Any())
            {
                var memoryAmount = Helper.GetTotalMemory();
                // Half of the installed memory in the system divided by 2, in GB
                var maxAllocatedMemory = (((memoryAmount - 2048000000) / 1024000000) / 2);
                // Number of processors
                var processorCount = Environment.ProcessorCount;
                var predictionClientMemoryNeededInGB = 3;
                var threadAmount = (int)(maxAllocatedMemory / (ulong)predictionClientMemoryNeededInGB);
                var chunkedDialogTopics = dialogueNeedingInferencing.Chunk(dialogueNeedingInferencing.Count / threadAmount).Select(chunk => chunk.ToDictionary(x => x.Key, x => x.Value)).ToList();
                Console.WriteLine($"Inferenced {cachedCount} records from pre-generated cache. {dialogueNeedingInferencing.Count} records remain uninferenced. Inferencing dialogue using LLM spread over {threadAmount} threads...");
                var sw = Stopwatch.StartNew();
                Task[] tasks = new Task[chunkedDialogTopics.Count];
                ConcurrentDictionary<string, string> localCache = new(selectedModel.LocalCache);
                int inferencedAmount = 0;
                for (int i = 0; i < chunkedDialogTopics.Count; i++)
                {
                    var currentDictionary = chunkedDialogTopics[i];
                    tasks[i] = Task.Run(() =>
                    {
                        var client = new InferencingClient(inferencorPath, Path.Combine(selectedModel.Directory.FullName, Consts.MODEL_SUBDIR_NAME), selectedModel.Prefix ?? string.Empty);
                        foreach (var (sourceText, dialogTopics) in currentDictionary)
                        {
                            var inferencedText = client.Inference(sourceText);
                            foreach (var dialogTopic in dialogTopics)
                            {
                                var copiedTopic = dialogTopic.DeepCopy();
                                copiedTopic.Name?.Set(Mutagen.Bethesda.Strings.Language.English, inferencedText);
                                state.PatchMod.DialogTopics.GetOrAddAsOverride(copiedTopic);
                            }
                            localCache.TryAdd(sourceText, inferencedText);
                            Interlocked.Increment(ref inferencedAmount);
                        }
                    });
                }
                /*
                _ = Task.Run(() =>
                {
                    while (inferencedAmount < dialogueNeedingInferencing.Count)
                    {
                        Thread.Sleep(30000);
                        Console.WriteLine($"Inferencing dialogue... {((int)(inferencedAmount / dialogueNeedingInferencing.Count * 100))}% done");
                    }
                });
                */
                Task.WhenAll(tasks).Wait();
                sw.Stop();
                Console.WriteLine($"Took {sw.Elapsed.TotalSeconds} sec to inference {dialogueNeedingInferencing.Count} records.");

                Console.WriteLine($"Saving cache for {localCache.Count} records...");
                Helper.WriteToFile(localCache.Select(x => new DialogueTextConversion(x.Key, x.Value)), Path.Combine(selectedModel.Directory.FullName, $"{Consts.LOCAL_CACHE_FILENAME}.{Consts.DATA_FORMAT}"));

                Console.WriteLine($"Done!");
            }
        }
    }
}
